{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "import unicodedata\n",
    "import urllib3\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 33000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sent):\n",
    "    sent = unicode_to_ascii(sent.lower())\n",
    "    sent = re.sub(r\"([?.!,¿])\",r\" \\1\", sent)\n",
    "    sent = re.sub(r\"[^a-zA-Z!.?]+\", r\" \", sent)\n",
    "    sent = re.sub(r\"\\s+\",\" \",sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have you had dinner ?\n",
      "avez vous deja dine ?\n"
     ]
    }
   ],
   "source": [
    "en_sent = u\"Have you had dinner?\"\n",
    "fr_sent = u\"Avez-vous déjà diné?\"\n",
    "print(preprocess_sentence(en_sent))\n",
    "print(preprocess_sentence(fr_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessed_data():\n",
    "    encoder_input, decoder_input, decoder_target = [], [], []\n",
    "    \n",
    "    with open('data/fra.txt', \"r\") as lines:\n",
    "        for i, line in enumerate(lines):\n",
    "            # source, target 분리\n",
    "            src_line, tar_line, _ = line.strip().split('\\t')\n",
    "            \n",
    "            # source 데이터 전처리\n",
    "            src_line_input = [w for w in preprocess_sentence(src_line).split()]\n",
    "            \n",
    "            # target 데이터 전처리\n",
    "            tar_line = preprocess_sentence(tar_line)\n",
    "            tar_line_input = [w for w in (\"<sos> \"+ tar_line).split()]\n",
    "            tar_line_target = [w for w in (tar_line + \" <eos>\").split()]\n",
    "            \n",
    "            encoder_input.append(src_line_input)\n",
    "            decoder_input.append(tar_line_input)\n",
    "            decoder_target.append(tar_line_target)\n",
    "            \n",
    "            if i == num_samples -1:\n",
    "                break\n",
    "                \n",
    "    return encoder_input, decoder_input, decoder_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['go', '.'], ['hi', '.'], ['hi', '.'], ['run', '!'], ['run', '!']]\n",
      "[['<sos>', 'va', '!'], ['<sos>', 'salut', '!'], ['<sos>', 'salut', '.'], ['<sos>', 'cours', '!'], ['<sos>', 'courez', '!']]\n",
      "[['va', '!', '<eos>'], ['salut', '!', '<eos>'], ['salut', '.', '<eos>'], ['cours', '!', '<eos>'], ['courez', '!', '<eos>']]\n"
     ]
    }
   ],
   "source": [
    "sents_en_in, sents_fra_in, sents_fra_out = load_preprocessed_data()\n",
    "print(sents_en_in[:5])\n",
    "print(sents_fra_in[:5])\n",
    "print(sents_fra_out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(filters = \"\", lower=False)\n",
    "tokenizer_en.fit_on_texts(sents_en_in)\n",
    "encoder_input = tokenizer_en.texts_to_sequences(sents_en_in)\n",
    "\n",
    "tokenizer_fra = Tokenizer(filters=\"\", lower = False)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_in)\n",
    "tokenizer_fra.fit_on_texts(sents_fra_out)\n",
    "decoder_input = tokenizer_fra.texts_to_sequences(sents_fra_in)\n",
    "decoder_target = tokenizer_fra.texts_to_sequences(sents_fra_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, padding=\"post\")\n",
    "decoder_input = pad_sequences(decoder_input, padding=\"post\")\n",
    "decoder_target = pad_sequences(decoder_target, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33000, 8)\n",
      "(33000, 16)\n",
      "(33000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input.shape)\n",
    "print(decoder_input.shape)\n",
    "print(decoder_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어 집합의 크기 : 4663, 프랑스어 단어 집합의 크기 : 8038\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "tar_vocab_size = len(tokenizer_fra.word_index) + 1\n",
    "print(f\"영어 단어 집합의 크기 : {src_vocab_size}, 프랑스어 단어 집합의 크기 : {tar_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = tokenizer_en.word_index\n",
    "index_to_src = tokenizer_en.index_word\n",
    "\n",
    "tar_to_index = tokenizer_fra.word_index\n",
    "index_to_tar = tokenizer_fra.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11475  9081 24948 ... 24342  3627  8690]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_of_val = int(num_samples *0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29700, 8)\n",
      "(29700, 16)\n",
      "(29700, 16)\n",
      "(3300, 8)\n",
      "(3300, 16)\n",
      "(3300, 16)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder_inputs = Input(shape=(None, ))\n",
    "enc_emb = Embedding(src_vocab_size, latent_dim)(encoder_inputs) # embedding\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder\n",
    "decoder_inputs = Input(shape=(None, ))\n",
    "dec_emb_layer = Embedding(tar_vocab_size, latent_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "dec_masking = Masking(mask_value = 0.0)(dec_emb)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(tar_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     233150      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 50)     401900      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 50)     0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "masking_2 (Masking)             (None, None, 50)     0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50), (None,  20200       masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 50), ( 20200       masking_2[0][0]                  \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8038)   409938      lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,085,388\n",
      "Trainable params: 1,085,388\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 원-핫 인코딩을 하지 않은 상태로, 정수 레이블에 대해서 \n",
    "# 다중 클래스 분류 문제를 풀고자 하는 경우에는 \n",
    "# categorical_crossentropy함수가 아니라 sparse_categorical_crossentropy를 사용하면 됩니다. \n",
    "# 이는 케라스에서 규정한 약속입니다.\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "233/233 [==============================] - 103s 441ms/step - loss: 3.1568 - acc: 0.6061 - val_loss: 1.9228 - val_acc: 0.6432\n",
      "Epoch 2/50\n",
      "233/233 [==============================] - 101s 434ms/step - loss: 1.7432 - acc: 0.7241 - val_loss: 1.6267 - val_acc: 0.7407\n",
      "Epoch 3/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 1.5502 - acc: 0.7486 - val_loss: 1.5250 - val_acc: 0.7564\n",
      "Epoch 4/50\n",
      "233/233 [==============================] - 100s 431ms/step - loss: 1.4395 - acc: 0.7639 - val_loss: 1.4237 - val_acc: 0.7694\n",
      "Epoch 5/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 1.3532 - acc: 0.7792 - val_loss: 1.3483 - val_acc: 0.7848\n",
      "Epoch 6/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 1.2909 - acc: 0.7889 - val_loss: 1.3113 - val_acc: 0.7896\n",
      "Epoch 7/50\n",
      "233/233 [==============================] - 99s 423ms/step - loss: 1.2408 - acc: 0.7955 - val_loss: 1.2686 - val_acc: 0.7959\n",
      "Epoch 8/50\n",
      "233/233 [==============================] - 100s 428ms/step - loss: 1.1968 - acc: 0.8024 - val_loss: 1.2335 - val_acc: 0.8027\n",
      "Epoch 9/50\n",
      "233/233 [==============================] - 100s 430ms/step - loss: 1.1567 - acc: 0.8082 - val_loss: 1.1961 - val_acc: 0.8083\n",
      "Epoch 10/50\n",
      "233/233 [==============================] - 100s 430ms/step - loss: 1.1223 - acc: 0.8129 - val_loss: 1.1697 - val_acc: 0.8118\n",
      "Epoch 11/50\n",
      "233/233 [==============================] - 99s 426ms/step - loss: 1.0914 - acc: 0.8171 - val_loss: 1.1491 - val_acc: 0.8155\n",
      "Epoch 12/50\n",
      "233/233 [==============================] - 100s 428ms/step - loss: 1.0640 - acc: 0.8208 - val_loss: 1.1363 - val_acc: 0.8172\n",
      "Epoch 13/50\n",
      "233/233 [==============================] - 100s 429ms/step - loss: 1.0390 - acc: 0.8243 - val_loss: 1.1078 - val_acc: 0.8205\n",
      "Epoch 14/50\n",
      "233/233 [==============================] - 99s 426ms/step - loss: 1.0163 - acc: 0.8276 - val_loss: 1.0932 - val_acc: 0.8231\n",
      "Epoch 15/50\n",
      "233/233 [==============================] - 101s 433ms/step - loss: 0.9951 - acc: 0.8304 - val_loss: 1.0944 - val_acc: 0.8241\n",
      "Epoch 16/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 0.9756 - acc: 0.8336 - val_loss: 1.0790 - val_acc: 0.8260\n",
      "Epoch 17/50\n",
      "233/233 [==============================] - 100s 431ms/step - loss: 0.9567 - acc: 0.8361 - val_loss: 1.0542 - val_acc: 0.8298\n",
      "Epoch 18/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 0.9382 - acc: 0.8389 - val_loss: 1.0338 - val_acc: 0.8327\n",
      "Epoch 19/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 0.9197 - acc: 0.8412 - val_loss: 1.0307 - val_acc: 0.8318\n",
      "Epoch 20/50\n",
      "233/233 [==============================] - 101s 432ms/step - loss: 0.9035 - acc: 0.8436 - val_loss: 1.0100 - val_acc: 0.8356\n",
      "Epoch 21/50\n",
      "233/233 [==============================] - 102s 437ms/step - loss: 0.8887 - acc: 0.8455 - val_loss: 1.0143 - val_acc: 0.8354\n",
      "Epoch 22/50\n",
      "233/233 [==============================] - 101s 433ms/step - loss: 0.8743 - acc: 0.8479 - val_loss: 0.9988 - val_acc: 0.8369\n",
      "Epoch 23/50\n",
      "233/233 [==============================] - 103s 444ms/step - loss: 0.8614 - acc: 0.8500 - val_loss: 0.9942 - val_acc: 0.8374\n",
      "Epoch 24/50\n",
      "233/233 [==============================] - 106s 453ms/step - loss: 0.8483 - acc: 0.8521 - val_loss: 0.9891 - val_acc: 0.8386\n",
      "Epoch 25/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.8362 - acc: 0.8542 - val_loss: 0.9686 - val_acc: 0.8418\n",
      "Epoch 26/50\n",
      "233/233 [==============================] - 99s 426ms/step - loss: 0.8245 - acc: 0.8561 - val_loss: 0.9746 - val_acc: 0.8400\n",
      "Epoch 27/50\n",
      "233/233 [==============================] - 99s 423ms/step - loss: 0.8135 - acc: 0.8575 - val_loss: 0.9723 - val_acc: 0.8412\n",
      "Epoch 28/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.8030 - acc: 0.8594 - val_loss: 0.9522 - val_acc: 0.8441\n",
      "Epoch 29/50\n",
      "233/233 [==============================] - 98s 422ms/step - loss: 0.7926 - acc: 0.8612 - val_loss: 0.9404 - val_acc: 0.8455\n",
      "Epoch 30/50\n",
      "233/233 [==============================] - 98s 422ms/step - loss: 0.7822 - acc: 0.8627 - val_loss: 0.9401 - val_acc: 0.8468\n",
      "Epoch 31/50\n",
      "233/233 [==============================] - 98s 422ms/step - loss: 0.7726 - acc: 0.8644 - val_loss: 0.9393 - val_acc: 0.8459\n",
      "Epoch 32/50\n",
      "233/233 [==============================] - 99s 423ms/step - loss: 0.7645 - acc: 0.8660 - val_loss: 0.9318 - val_acc: 0.8477\n",
      "Epoch 33/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.7566 - acc: 0.8674 - val_loss: 0.9297 - val_acc: 0.8477\n",
      "Epoch 34/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.7494 - acc: 0.8689 - val_loss: 0.9284 - val_acc: 0.8487\n",
      "Epoch 35/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.7423 - acc: 0.8705 - val_loss: 0.9225 - val_acc: 0.8492\n",
      "Epoch 36/50\n",
      "233/233 [==============================] - 100s 429ms/step - loss: 0.7357 - acc: 0.8720 - val_loss: 0.9196 - val_acc: 0.8501\n",
      "Epoch 37/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.7295 - acc: 0.8734 - val_loss: 0.9191 - val_acc: 0.8502\n",
      "Epoch 38/50\n",
      "233/233 [==============================] - 99s 425ms/step - loss: 0.7231 - acc: 0.8747 - val_loss: 0.9160 - val_acc: 0.8504\n",
      "Epoch 39/50\n",
      "233/233 [==============================] - 99s 427ms/step - loss: 0.7166 - acc: 0.8758 - val_loss: 0.9169 - val_acc: 0.8511\n",
      "Epoch 40/50\n",
      "233/233 [==============================] - 100s 427ms/step - loss: 0.7109 - acc: 0.8771 - val_loss: 0.9113 - val_acc: 0.8514\n",
      "Epoch 41/50\n",
      "233/233 [==============================] - 99s 425ms/step - loss: 0.7050 - acc: 0.8783 - val_loss: 0.9159 - val_acc: 0.8508\n",
      "Epoch 42/50\n",
      "233/233 [==============================] - 99s 424ms/step - loss: 0.6992 - acc: 0.8797 - val_loss: 0.9060 - val_acc: 0.8539\n",
      "Epoch 43/50\n",
      "233/233 [==============================] - 99s 425ms/step - loss: 0.6936 - acc: 0.8808 - val_loss: 0.8981 - val_acc: 0.8545\n",
      "Epoch 44/50\n",
      "233/233 [==============================] - 99s 425ms/step - loss: 0.6881 - acc: 0.8818 - val_loss: 0.9001 - val_acc: 0.8547\n",
      "Epoch 45/50\n",
      "233/233 [==============================] - 99s 426ms/step - loss: 0.6828 - acc: 0.8830 - val_loss: 0.8942 - val_acc: 0.8558\n",
      "Epoch 46/50\n",
      "233/233 [==============================] - 99s 425ms/step - loss: 0.6776 - acc: 0.8840 - val_loss: 0.8988 - val_acc: 0.8541\n",
      "Epoch 47/50\n",
      "233/233 [==============================] - 108s 466ms/step - loss: 0.6723 - acc: 0.8850 - val_loss: 0.8942 - val_acc: 0.8551\n",
      "Epoch 48/50\n",
      "233/233 [==============================] - 101s 431ms/step - loss: 0.6673 - acc: 0.8859 - val_loss: 0.8975 - val_acc: 0.8555\n",
      "Epoch 49/50\n",
      "233/233 [==============================] - 99s 423ms/step - loss: 0.6622 - acc: 0.8867 - val_loss: 0.8869 - val_acc: 0.8567\n",
      "Epoch 50/50\n",
      "233/233 [==============================] - 99s 423ms/step - loss: 0.6572 - acc: 0.8878 - val_loss: 0.8886 - val_acc: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff9fa944dc0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = [encoder_input_train, decoder_input_train], \n",
    "          y = decoder_target_train,\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2= decoder_dense(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0,0] = tar_to_index['<sos>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    while not stop_condition_condition_condition_condition_condition_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] +  states_value)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "        \n",
    "        if (sampled_char == '<eos>' or len(decoded_sentence) > 50):\n",
    "            stop_condition= True\n",
    "            \n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0,0] = sampled_token_index\n",
    "        \n",
    "        states_value = [h,c]\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시ㅜ컨스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp =''\n",
    "    for i in input_seq:\n",
    "        if(i != 0):\n",
    "            temp = temp + index_to_src[i] + ' '\n",
    "    return temp\n",
    "\n",
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp = ''\n",
    "    for i in input_seq:\n",
    "        if( i != 0 and i != tar_to_index['<sos>'] and i != tar_to_index['<eos>']):\n",
    "            temp = temp + index_to_tar[i] + ' '\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  i did a good job . \n",
      "번역문 : j ai fait du bon travail . \n",
      "예측문 :  j ai fait un bon boulot . \n",
      "\n",
      "\n",
      "원문 :  be nice . \n",
      "번역문 : soyez gentilles ! \n",
      "예측문 :  soyez bien ! \n",
      "\n",
      "\n",
      "원문 :  i like turtles . \n",
      "번역문 : j aime les tortues . \n",
      "예측문 :  j aime les tout . \n",
      "\n",
      "\n",
      "원문 :  do you eat a lot ? \n",
      "번역문 : mangez vous beaucoup ? \n",
      "예측문 :  as tu du cafe ? \n",
      "\n",
      "\n",
      "원문 :  once again . \n",
      "번역문 : encore une fois . \n",
      "예측문 :  fais une fois . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50, 100, 300, 1001]:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequencece(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_train[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_train[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  why is snow white ? \n",
      "번역문 : pourquoi la neige est elle blanche ? \n",
      "예측문 :  est ce que est il ete occupe ? \n",
      "\n",
      "\n",
      "원문 :  drive on . \n",
      "번역문 : avancez ! \n",
      "예측문 :  d accord qui vous . \n",
      "\n",
      "\n",
      "원문 :  do you have the key ? \n",
      "번역문 : as tu la cle ? \n",
      "예측문 :  avez vous l air assez ? \n",
      "\n",
      "\n",
      "원문 :  they re wrong . \n",
      "번역문 : ils ont tort ! \n",
      "예측문 :  ils sont des qui . \n",
      "\n",
      "\n",
      "원문 :  i got a bargain . \n",
      "번역문 : j ai fait une affaire . \n",
      "예측문 :  j ai une voiture . \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [3,50,100,300,1001]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "\n",
    "    print(\"원문 : \",seq2src(encoder_input_test[seq_index]))\n",
    "    print(\"번역문 :\",seq2tar(decoder_input_test[seq_index]))\n",
    "    print(\"예측문 :\",decoded_sentence[:-5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
